{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Data Preprocessing\n",
        "def preprocess_data(train_path, test_path):\n",
        "    # Read in the data\n",
        "    train = pd.read_csv(train_path)\n",
        "    test = pd.read_csv(test_path)\n",
        "\n",
        "    # Combine train and test data for consistent preprocessing\n",
        "    train['is_train'] = 1\n",
        "    test['is_train'] = 0\n",
        "    data = pd.concat([train, test], sort=False)\n",
        "\n",
        "    # Drop unnecessary columns\n",
        "    data = data.drop(columns=['Surname', 'CustomerId', 'id'])\n",
        "\n",
        "    # Handle missing values for numerical features\n",
        "    numerical_cols = ['CreditScore', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'EstimatedSalary']\n",
        "    data[numerical_cols] = data[numerical_cols].fillna(data[numerical_cols].median())\n",
        "\n",
        "    # Handle missing values for categorical features\n",
        "    categorical_cols = ['Geography', 'Gender']\n",
        "    for col in categorical_cols:\n",
        "        data[col] = data[col].fillna(data[col].mode()[0])\n",
        "\n",
        "    # One-hot encode categorical features using pd.get_dummies\n",
        "    data = pd.get_dummies(data, columns=categorical_cols, drop_first=True)\n",
        "\n",
        "    # Scale numerical features using z-score normalization\n",
        "    for col in numerical_cols:\n",
        "        mean = data[col].mean()\n",
        "        std = data[col].std()\n",
        "        data[col] = (data[col] - mean) / std\n",
        "\n",
        "    # Split back into train and test sets\n",
        "    train_data = data[data['is_train'] == 1].drop(columns=['is_train'])\n",
        "    test_data = data[data['is_train'] == 0].drop(columns=['is_train', 'Exited'])\n",
        "\n",
        "    # Separate features and target\n",
        "    X_train = train_data.drop(columns=['Exited']).values\n",
        "    y_train = train_data['Exited'].values\n",
        "    X_test = test_data.values\n",
        "    test_ids = test['id'].values\n",
        "\n",
        "    return X_train, y_train, X_test, test_ids\n",
        "\n",
        "# KNN Class Definition\n",
        "class KNN:\n",
        "    def __init__(self, k=3, distance_metric='euclidean'):\n",
        "        self.k = k\n",
        "        self.distance_metric = distance_metric\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.X_train = X\n",
        "        self.y_train = y\n",
        "\n",
        "    def compute_distance(self, x):\n",
        "        if self.distance_metric == 'euclidean':\n",
        "            return np.sqrt(np.sum((self.X_train - x) ** 2, axis=1))\n",
        "        elif self.distance_metric == 'manhattan':\n",
        "            return np.sum(np.abs(self.X_train - x), axis=1)\n",
        "        else:\n",
        "            raise ValueError(f\"Unsupported distance metric: {self.distance_metric}\")\n",
        "\n",
        "    def predict_proba(self, X):\n",
        "        probabilities = []\n",
        "        for x in X:\n",
        "            distances = self.compute_distance(x)\n",
        "            k_indices = np.argsort(distances)[:self.k]\n",
        "            k_nearest_labels = self.y_train[k_indices]\n",
        "            prob_1 = np.sum(k_nearest_labels) / self.k\n",
        "            probabilities.append([1 - prob_1, prob_1])\n",
        "        return np.array(probabilities)\n",
        "\n",
        "    def predict(self, X):\n",
        "        proba = self.predict_proba(X)\n",
        "        return (proba[:, 1] >= 0.5).astype(int)\n",
        "\n",
        "# Stratified K-Fold Cross-Validation\n",
        "def stratified_k_fold_split(X, y, n_splits=5, random_state=42):\n",
        "    np.random.seed(random_state)\n",
        "    y = np.array(y)\n",
        "    classes, y_indices = np.unique(y, return_inverse=True)\n",
        "    n_classes = len(classes)\n",
        "    class_counts = np.bincount(y_indices)\n",
        "    folds = [[] for _ in range(n_splits)]\n",
        "    for cls in range(n_classes):\n",
        "        idxs = np.where(y_indices == cls)[0]\n",
        "        np.random.shuffle(idxs)\n",
        "        fold_sizes = (len(idxs) // n_splits) * np.ones(n_splits, dtype=int)\n",
        "        fold_sizes[:len(idxs) % n_splits] += 1\n",
        "        current = 0\n",
        "        for fold_idx, fold_size in enumerate(fold_sizes):\n",
        "            start, stop = current, current + fold_size\n",
        "            folds[fold_idx].extend(idxs[start:stop])\n",
        "            current = stop\n",
        "    splits = []\n",
        "    for fold_idx in range(n_splits):\n",
        "        test_indices = np.array(folds[fold_idx])\n",
        "        train_indices = np.array([i for i in range(len(X)) if i not in test_indices])\n",
        "        splits.append((train_indices, test_indices))\n",
        "    return splits\n",
        "\n",
        "# ROC AUC Score Implementation\n",
        "def roc_auc_score_manual(y_true, y_scores):\n",
        "    # Ensure arrays are numpy arrays\n",
        "    y_true = np.array(y_true)\n",
        "    y_scores = np.array(y_scores)\n",
        "\n",
        "    # Sort scores and corresponding true labels in descending order\n",
        "    desc_order = np.argsort(-y_scores)\n",
        "    y_true = y_true[desc_order]\n",
        "    y_scores = y_scores[desc_order]\n",
        "\n",
        "    # Compute true positive rates (tpr) and false positive rates (fpr)\n",
        "    tps = np.cumsum(y_true)\n",
        "    fps = np.cumsum(1 - y_true)\n",
        "    tpr = tps / tps[-1]\n",
        "    fpr = fps / fps[-1]\n",
        "\n",
        "    # Add (0,0) point\n",
        "    tpr = np.concatenate([[0], tpr])\n",
        "    fpr = np.concatenate([[0], fpr])\n",
        "\n",
        "    # Compute AUC using the trapezoidal rule\n",
        "    auc = np.trapz(tpr, fpr)\n",
        "    return auc\n",
        "\n",
        "# Cross-Validation Function\n",
        "def cross_validate(X, y, knn, n_splits=5):\n",
        "    splits = stratified_k_fold_split(X, y, n_splits)\n",
        "    auc_scores = []\n",
        "    for fold_idx, (train_idx, val_idx) in enumerate(splits):\n",
        "        X_train_cv, X_val_cv = X[train_idx], X[val_idx]\n",
        "        y_train_cv, y_val_cv = y[train_idx], y[val_idx]\n",
        "        knn.fit(X_train_cv, y_train_cv)\n",
        "        y_val_proba = knn.predict_proba(X_val_cv)[:, 1]\n",
        "        auc = roc_auc_score_manual(y_val_cv, y_val_proba)\n",
        "        auc_scores.append(auc)\n",
        "        print(f\"Fold {fold_idx + 1} AUC: {auc:.4f}\")\n",
        "    mean_auc = np.mean(auc_scores)\n",
        "    print(f\"\\nMean AUC: {mean_auc:.4f}\")\n",
        "    return mean_auc\n",
        "\n",
        "# Load and preprocess data\n",
        "X, y, X_test, test_ids = preprocess_data('train.csv', 'test.csv')\n",
        "\n",
        "# Ensure data is numpy array\n",
        "X = np.array(X, dtype=float)\n",
        "y = np.array(y, dtype=int)\n",
        "X_test = np.array(X_test, dtype=float)\n",
        "\n",
        "# Hyperparameter Tuning\n",
        "k_values = [24, 25, 26, 27, 28]\n",
        "distance_metrics = ['euclidean', 'manhattan']\n",
        "best_auc = 0\n",
        "best_k = None\n",
        "best_metric = None\n",
        "\n",
        "for k in k_values:\n",
        "    for metric in distance_metrics:\n",
        "        print(f\"\\nEvaluating k={k}, metric={metric}\")\n",
        "        knn = KNN(k=k, distance_metric=metric)\n",
        "        mean_auc = cross_validate(X, y, knn, n_splits=5)\n",
        "        if mean_auc > best_auc:\n",
        "            best_auc = mean_auc\n",
        "            best_k = k\n",
        "            best_metric = metric\n",
        "\n",
        "print(f\"\\nBest hyperparameters: k={best_k}, metric={best_metric}, AUC={best_auc:.4f}\")\n",
        "\n",
        "# Train final model on full training data\n",
        "knn = KNN(k=best_k, distance_metric=best_metric)\n",
        "knn.fit(X, y)\n",
        "\n",
        "# Predict on test data\n",
        "test_proba = knn.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Prepare submission\n",
        "submission = pd.DataFrame({\n",
        "    'id': test_ids,\n",
        "    'Exited': test_proba  # Use probabilities for better granularity\n",
        "})\n",
        "submission.to_csv('submissions.csv', index=False)\n",
        "print(\"Submission file 'submissions.csv' created.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "czVAbJPlLdcd",
        "outputId": "f56da463-fbf6-4135-cef7-220c2c502317"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluating k=24, metric=euclidean\n",
            "Fold 1 AUC: 0.9151\n",
            "Fold 2 AUC: 0.9085\n",
            "Fold 3 AUC: 0.9202\n",
            "Fold 4 AUC: 0.9254\n",
            "Fold 5 AUC: 0.9240\n",
            "\n",
            "Mean AUC: 0.9186\n",
            "\n",
            "Evaluating k=24, metric=manhattan\n",
            "Fold 1 AUC: 0.9131\n",
            "Fold 2 AUC: 0.9088\n",
            "Fold 3 AUC: 0.9172\n",
            "Fold 4 AUC: 0.9260\n",
            "Fold 5 AUC: 0.9186\n",
            "\n",
            "Mean AUC: 0.9167\n",
            "\n",
            "Evaluating k=25, metric=euclidean\n",
            "Fold 1 AUC: 0.9152\n",
            "Fold 2 AUC: 0.9089\n",
            "Fold 3 AUC: 0.9203\n",
            "Fold 4 AUC: 0.9262\n",
            "Fold 5 AUC: 0.9232\n",
            "\n",
            "Mean AUC: 0.9188\n",
            "\n",
            "Evaluating k=25, metric=manhattan\n",
            "Fold 1 AUC: 0.9128\n",
            "Fold 2 AUC: 0.9074\n",
            "Fold 3 AUC: 0.9165\n",
            "Fold 4 AUC: 0.9269\n",
            "Fold 5 AUC: 0.9185\n",
            "\n",
            "Mean AUC: 0.9164\n",
            "\n",
            "Evaluating k=26, metric=euclidean\n",
            "Fold 1 AUC: 0.9145\n",
            "Fold 2 AUC: 0.9085\n",
            "Fold 3 AUC: 0.9203\n",
            "Fold 4 AUC: 0.9265\n",
            "Fold 5 AUC: 0.9238\n",
            "\n",
            "Mean AUC: 0.9187\n",
            "\n",
            "Evaluating k=26, metric=manhattan\n",
            "Fold 1 AUC: 0.9115\n",
            "Fold 2 AUC: 0.9085\n",
            "Fold 3 AUC: 0.9177\n",
            "Fold 4 AUC: 0.9258\n",
            "Fold 5 AUC: 0.9195\n",
            "\n",
            "Mean AUC: 0.9166\n",
            "\n",
            "Evaluating k=27, metric=euclidean\n",
            "Fold 1 AUC: 0.9154\n",
            "Fold 2 AUC: 0.9091\n",
            "Fold 3 AUC: 0.9213\n",
            "Fold 4 AUC: 0.9258\n",
            "Fold 5 AUC: 0.9240\n",
            "\n",
            "Mean AUC: 0.9191\n",
            "\n",
            "Evaluating k=27, metric=manhattan\n",
            "Fold 1 AUC: 0.9112\n",
            "Fold 2 AUC: 0.9085\n",
            "Fold 3 AUC: 0.9179\n",
            "Fold 4 AUC: 0.9263\n",
            "Fold 5 AUC: 0.9194\n",
            "\n",
            "Mean AUC: 0.9167\n",
            "\n",
            "Evaluating k=28, metric=euclidean\n",
            "Fold 1 AUC: 0.9140\n",
            "Fold 2 AUC: 0.9089\n",
            "Fold 3 AUC: 0.9205\n",
            "Fold 4 AUC: 0.9258\n",
            "Fold 5 AUC: 0.9232\n",
            "\n",
            "Mean AUC: 0.9185\n",
            "\n",
            "Evaluating k=28, metric=manhattan\n",
            "Fold 1 AUC: 0.9120\n",
            "Fold 2 AUC: 0.9089\n",
            "Fold 3 AUC: 0.9172\n",
            "Fold 4 AUC: 0.9265\n",
            "Fold 5 AUC: 0.9198\n",
            "\n",
            "Mean AUC: 0.9169\n",
            "\n",
            "Best hyperparameters: k=27, metric=euclidean, AUC=0.9191\n",
            "Submission file 'submissions.csv' created.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}